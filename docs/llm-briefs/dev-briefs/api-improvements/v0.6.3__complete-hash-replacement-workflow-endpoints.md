# Technical Brief: Complete Hash Replacement Workflow Endpoints


## üìã Document Overview

**Project**: MGraph-AI__Service__Html   
**Version**: v0.6.3  
**Date**: 2025-10-18  
**Purpose**: Add missing REST API endpoints to enable complete text hash replacement workflow  
**Implementation Approach**: Additive only - NO changes to existing endpoints  
**Target Audience**: LLM implementing these changes in a separate session  

---

## üéØ Objectives

### Primary Goal
Add new REST API endpoints that complete the hash replacement workflow by providing the exact data structures needed by the existing `/hashes/to__html` endpoint.

### Success Criteria
‚úÖ New endpoints return data compatible with `Schema__Hashes__To__Html__Request`  
‚úÖ Zero modifications to existing endpoints  
‚úÖ Workflow reduces API calls from 3 to 1-2  
‚úÖ All type-safe schemas properly defined  
‚úÖ Full test coverage  

---

## üìö Context & Background

### Current Service Architecture

The MGraph-AI__Service__Html is a FastAPI service that provides HTML transformation capabilities. It has three main route groups:

1. **HTML Routes** (`/html/*`) - Parse and transform HTML
2. **Dict Routes** (`/dict/*`) - Work with html_dict structures  
3. **Hashes Routes** (`/hashes/*`) - Apply hash mappings to reconstruct HTML

### The Problem: Incomplete Workflow

Currently, the `/hashes/to__html` endpoint expects this request:

```python
class Schema__Hashes__To__Html__Request(Type_Safe):
    html_dict   : Dict                          # html_dict with text replaced by hashes
    hash_mapping: Dict[Safe_Str__Hash, str]     # {hash: replacement_text}
```

**However**, there is NO endpoint that returns:
- `html_dict` with text already replaced by hashes
- `text_hashes_mapping` in the format `Dict[hash, text]`

### Current (Broken) Workflow

```
Step 1: POST /html/to__dict
Input:  { html: "<p>Hello</p>" }
Output: { html_dict: {...}, node_count: 5 }
        ‚ùå html_dict has ORIGINAL TEXT, not hashes

Step 2: POST /html/to__text__nodes
Input:  { html: "<p>Hello</p>" }
Output: { text_nodes: {"abc123": {"text": "Hello", "tag": "p"}} }
        ‚ùå Wrong format - need Dict[hash, str], not Dict[hash, Dict]
        ‚ùå html_dict not returned at all

Step 3: User edits hash_mapping manually
        ‚ùå Hard to construct - must extract from text_nodes

Step 4: POST /hashes/to__html
Input:  { html_dict: <from Step 1>, hash_mapping: {...} }
        ‚ùå FAILS - html_dict has "Hello", not hash "abc123"
```

### Root Cause Analysis

The `Html__Extract_Text_Nodes` class modifies `html_dict` in-place during traversal:

```python
def capture_text(self, text, tag):
    hash_value = str_md5(text)[:self.hash_size]
    self.text_elements__raw[hash_value] = text
    node['data'] = self.capture_text(...)  # ‚Üê REPLACES text with hash IN-PLACE
```

But no endpoint returns this modified `html_dict`!

---

## üîß Solution: New Endpoints

### Overview

Add **TWO new endpoints** without modifying any existing code:

1. **`POST /html/to__dict__hashes`** - Returns html_dict with text as hashes + simple hash‚Üítext mapping
2. **`POST /html/to__text__hashes`** - Returns only text hashes mapping (efficient, lightweight)

### Endpoint 1: `/html/to__dict__hashes` ‚≠ê PRIMARY

**Purpose**: One-stop endpoint that returns everything needed for hash replacement workflow

**Request Schema**: `Schema__Html__To__Dict__Hashes__Request`
```python
from osbot_utils.type_safe.Type_Safe                                       import Type_Safe
from osbot_utils.type_safe.primitives.core.Safe_UInt                       import Safe_UInt
from osbot_utils.type_safe.primitives.domains.web.safe_str.Safe_Str__Html import Safe_Str__Html

class Schema__Html__To__Dict__Hashes__Request(Type_Safe):
    """Parse HTML and replace text with hashes"""
    html     : Safe_Str__Html
    max_depth: Safe_UInt = 256
```

**Response Schema**: `Schema__Html__To__Dict__Hashes__Response`
```python
from osbot_utils.type_safe.Type_Safe                                                import Type_Safe
from osbot_utils.type_safe.primitives.domains.cryptography.safe_str.Safe_Str__Hash import Safe_Str__Hash
from osbot_utils.type_safe.primitives.core.Safe_UInt                               import Safe_UInt
from typing                                                                         import Dict

class Schema__Html__To__Dict__Hashes__Response(Type_Safe):
    """Complete package for hash replacement workflow"""
    
    # Core data (compatible with Schema__Hashes__To__Html__Request)
    html_dict            : Dict                              # With text replaced by hashes ‚≠ê
    text_hashes_mapping  : Dict[Safe_Str__Hash, str]         # Simple {hash: text} ‚≠ê
    
    # Metadata
    node_count           : Safe_UInt
    max_depth            : Safe_UInt
    total_text_hashes    : Safe_UInt
    max_depth_reached    : bool
```

**Implementation Location**: `Routes__Html.to__dict__hashes()`

**Implementation Logic**:
```python
def to__dict__hashes(self, request: Schema__Html__To__Dict__Hashes__Request
                     ) -> Schema__Html__To__Dict__Hashes__Response:
    """
    Parse HTML and replace all text content with 10-char hashes.
    Returns html_dict with hashes + simple hash‚Üítext mapping.
    """
    
    # Step 1: Parse HTML to html_dict
    html_dict = self.html_direct_transformations.html__to__html_dict(request.html)
    
    # Step 2: Extract text nodes (THIS MODIFIES html_dict in-place!)
    extractor = Html__Extract_Text_Nodes()
    extractor.html_dict = html_dict
    extractor.max_depth = request.max_depth
    extractor.traverse(html_dict, depth=0, parent_tag=None)
    
    # Step 3: Get simple hash‚Üítext mapping
    # extractor.text_elements__raw already has this format!
    text_hashes_mapping = extractor.text_elements__raw
    
    # Step 4: Calculate metrics
    node_count = self._count_nodes(html_dict)
    max_depth_val = self._calculate_max_depth(html_dict)
    
    # Step 5: Return
    return Schema__Html__To__Dict__Hashes__Response(
        html_dict            = html_dict,              # ‚Üê Text already replaced!
        text_hashes_mapping  = text_hashes_mapping,    # ‚Üê Simple format!
        node_count           = node_count,
        max_depth            = max_depth_val,
        total_text_hashes    = len(text_hashes_mapping),
        max_depth_reached    = self._check_depth(html_dict, request.max_depth)
    )
```

**Route Registration**: Add to `Routes__Html.setup_routes()`:
```python
def setup_routes(self):
    self.add_route_post(self.to__dict         )
    self.add_route_post(self.to__html         )
    self.add_route_post(self.to__text__nodes  )
    self.add_route_post(self.to__lines        )
    self.add_route_post(self.to__html__hashes )
    self.add_route_post(self.to__html__xxx    )
    self.add_route_post(self.to__dict__hashes )  # ‚Üê NEW
```

---

### Endpoint 2: `/html/to__text__hashes` üîπ LIGHTWEIGHT

**Purpose**: Efficient endpoint that returns only the hash‚Üítext mapping (no html_dict)

**Request Schema**: `Schema__Html__To__Text__Hashes__Request`
```python
from osbot_utils.type_safe.Type_Safe                                       import Type_Safe
from osbot_utils.type_safe.primitives.core.Safe_UInt                       import Safe_UInt
from osbot_utils.type_safe.primitives.domains.web.safe_str.Safe_Str__Html import Safe_Str__Html

class Schema__Html__To__Text__Hashes__Request(Type_Safe):
    """Extract only text hashes mapping (lightweight)"""
    html     : Safe_Str__Html
    max_depth: Safe_UInt = 256
```

**Response Schema**: `Schema__Html__To__Text__Hashes__Response`
```python
from osbot_utils.type_safe.Type_Safe                                                import Type_Safe
from osbot_utils.type_safe.primitives.domains.cryptography.safe_str.Safe_Str__Hash import Safe_Str__Hash
from osbot_utils.type_safe.primitives.core.Safe_UInt                               import Safe_UInt
from typing                                                                         import Dict

class Schema__Html__To__Text__Hashes__Response(Type_Safe):
    """Simple hash mapping only"""
    
    text_hashes_mapping  : Dict[Safe_Str__Hash, str]  # {hash: text}
    total_text_hashes    : Safe_UInt
    max_depth_reached    : bool
```

**Implementation Location**: `Routes__Html.to__text__hashes()`

**Implementation Logic**:
```python
def to__text__hashes(self, request: Schema__Html__To__Text__Hashes__Request
                      ) -> Schema__Html__To__Text__Hashes__Response:
    """
    Extract only text‚Üíhash mapping without returning html_dict.
    Lightweight alternative when you only need the mapping.
    """
    
    # Step 1: Parse HTML
    html_dict = self.html_direct_transformations.html__to__html_dict(request.html)
    
    # Step 2: Extract text nodes
    extractor = Html__Extract_Text_Nodes()
    extractor.html_dict = html_dict
    extractor.max_depth = request.max_depth
    extractor.traverse(html_dict, depth=0, parent_tag=None)
    
    # Step 3: Get mapping
    text_hashes_mapping = extractor.text_elements__raw
    
    # Step 4: Return lightweight response
    return Schema__Html__To__Text__Hashes__Response(
        text_hashes_mapping  = text_hashes_mapping,
        total_text_hashes    = len(text_hashes_mapping),
        max_depth_reached    = self._check_depth(html_dict, request.max_depth)
    )
```

**Route Registration**: Add to `Routes__Html.setup_routes()`:
```python
def setup_routes(self):
    self.add_route_post(self.to__dict         )
    self.add_route_post(self.to__html         )
    self.add_route_post(self.to__text__nodes  )
    self.add_route_post(self.to__lines        )
    self.add_route_post(self.to__html__hashes )
    self.add_route_post(self.to__html__xxx    )
    self.add_route_post(self.to__dict__hashes )  # ‚Üê NEW
    self.add_route_post(self.to__text__hashes )  # ‚Üê NEW
```

---

## üìÅ File Structure

### New Files to Create

```
mgraph_ai_service_html/
‚îú‚îÄ‚îÄ html__fast_api/
‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Routes__Html.py                          # MODIFY: Add 2 new methods
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ schemas/
‚îÇ       ‚îú‚îÄ‚îÄ html/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ Schema__Html__To__Dict__Hashes__Request.py      # NEW
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ Schema__Html__To__Dict__Hashes__Response.py     # NEW
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ Schema__Html__To__Text__Hashes__Request.py      # NEW
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ Schema__Html__To__Text__Hashes__Response.py     # NEW
‚îÇ       ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ hashes/
‚îÇ           ‚îî‚îÄ‚îÄ (existing files - NO CHANGES)
```

---

## üíª Complete Implementation Code

### File 1: `Schema__Html__To__Dict__Hashes__Request.py`

```python
"""
Request schema for /html/to__dict__hashes endpoint
Parses HTML and replaces text with hashes
"""
from osbot_utils.type_safe.Type_Safe                                       import Type_Safe
from osbot_utils.type_safe.primitives.core.Safe_UInt                       import Safe_UInt
from osbot_utils.type_safe.primitives.domains.web.safe_str.Safe_Str__Html import Safe_Str__Html


class Schema__Html__To__Dict__Hashes__Request(Type_Safe):
    """Parse HTML and replace text content with 10-char hashes"""
    html     : Safe_Str__Html                           # Raw HTML content
    max_depth: Safe_UInt = 256                          # Maximum traversal depth
```

---

### File 2: `Schema__Html__To__Dict__Hashes__Response.py`

```python
"""
Response schema for /html/to__dict__hashes endpoint
Returns html_dict with text as hashes + simple mapping
"""
from osbot_utils.type_safe.Type_Safe                                                import Type_Safe
from osbot_utils.type_safe.primitives.domains.cryptography.safe_str.Safe_Str__Hash import Safe_Str__Hash
from osbot_utils.type_safe.primitives.core.Safe_UInt                               import Safe_UInt
from typing                                                                         import Dict


class Schema__Html__To__Dict__Hashes__Response(Type_Safe):
    """Complete data for hash replacement workflow"""
    
    # Core data structures
    html_dict            : Dict                              # html_dict with text replaced by hashes
    text_hashes_mapping  : Dict[Safe_Str__Hash, str]         # Simple {hash: text} mapping
    
    # Metadata
    node_count           : Safe_UInt                         # Total nodes in tree
    max_depth            : Safe_UInt                         # Deepest nesting level
    total_text_hashes    : Safe_UInt                         # Number of text nodes found
    max_depth_reached    : bool                              # Hit depth limit?
```

---

### File 3: `Schema__Html__To__Text__Hashes__Request.py`

```python
"""
Request schema for /html/to__text__hashes endpoint
Extracts only text hash mapping (lightweight)
"""
from osbot_utils.type_safe.Type_Safe                                       import Type_Safe
from osbot_utils.type_safe.primitives.core.Safe_UInt                       import Safe_UInt
from osbot_utils.type_safe.primitives.domains.web.safe_str.Safe_Str__Html import Safe_Str__Html


class Schema__Html__To__Text__Hashes__Request(Type_Safe):
    """Extract text hashes without returning html_dict"""
    html     : Safe_Str__Html                           # Raw HTML content
    max_depth: Safe_UInt = 256                          # Maximum traversal depth
```

---

### File 4: `Schema__Html__To__Text__Hashes__Response.py`

```python
"""
Response schema for /html/to__text__hashes endpoint
Returns only the text hash mapping (no html_dict)
"""
from osbot_utils.type_safe.Type_Safe                                                import Type_Safe
from osbot_utils.type_safe.primitives.domains.cryptography.safe_str.Safe_Str__Hash import Safe_Str__Hash
from osbot_utils.type_safe.primitives.core.Safe_UInt                               import Safe_UInt
from typing                                                                         import Dict


class Schema__Html__To__Text__Hashes__Response(Type_Safe):
    """Lightweight response with only hash mapping"""
    
    text_hashes_mapping  : Dict[Safe_Str__Hash, str]         # {hash: text} mapping
    total_text_hashes    : Safe_UInt                         # Number of text nodes
    max_depth_reached    : bool                              # Hit depth limit?
```

---

### File 5: Modifications to `Routes__Html.py`

**ADD these imports at the top:**
```python
from mgraph_ai_service_html.html__fast_api.schemas.html.Schema__Html__To__Dict__Hashes__Request  import Schema__Html__To__Dict__Hashes__Request
from mgraph_ai_service_html.html__fast_api.schemas.html.Schema__Html__To__Dict__Hashes__Response import Schema__Html__To__Dict__Hashes__Response
from mgraph_ai_service_html.html__fast_api.schemas.html.Schema__Html__To__Text__Hashes__Request  import Schema__Html__To__Text__Hashes__Request
from mgraph_ai_service_html.html__fast_api.schemas.html.Schema__Html__To__Text__Hashes__Response import Schema__Html__To__Text__Hashes__Response
from mgraph_ai_service_html.html__fast_api.core.Html__Extract_Text_Nodes                         import Html__Extract_Text_Nodes
```

**ADD these two methods to the `Routes__Html` class:**

```python
def to__dict__hashes(self, request: Schema__Html__To__Dict__Hashes__Request
                      ) -> Schema__Html__To__Dict__Hashes__Response:
    """
    Parse HTML and replace all text content with 10-char hashes.
    
    This is the PRIMARY endpoint for the hash replacement workflow.
    It returns:
    1. html_dict with text replaced by hashes (ready for /hashes/to__html)
    2. text_hashes_mapping in format {hash: text} (ready for user edits)
    
    Workflow:
    1. Call this endpoint with HTML
    2. User modifies text_hashes_mapping to create hash_mapping
    3. Call /hashes/to__html with html_dict + hash_mapping
    4. Get modified HTML
    """
    # Parse HTML to dict
    html_dict = self.html_direct_transformations.html__to__html_dict(request.html)
    
    # Extract text nodes - THIS MODIFIES html_dict IN-PLACE
    # After this, html_dict has hashes instead of text
    extractor = Html__Extract_Text_Nodes()
    extractor.html_dict = html_dict
    extractor.max_depth = request.max_depth
    extractor.traverse(html_dict, depth=0, parent_tag=None)
    
    # Get simple hash‚Üítext mapping
    # extractor.text_elements__raw has format {hash: text}
    text_hashes_mapping = extractor.text_elements__raw
    
    # Calculate metrics
    node_count = self._count_nodes(html_dict)
    max_depth_val = self._calculate_max_depth(html_dict)
    
    return Schema__Html__To__Dict__Hashes__Response(
        html_dict            = html_dict,
        text_hashes_mapping  = text_hashes_mapping,
        node_count           = node_count,
        max_depth            = max_depth_val,
        total_text_hashes    = len(text_hashes_mapping),
        max_depth_reached    = self._check_depth(html_dict, request.max_depth)
    )

def to__text__hashes(self, request: Schema__Html__To__Text__Hashes__Request
                      ) -> Schema__Html__To__Text__Hashes__Response:
    """
    Extract only the text hash mapping without returning html_dict.
    
    This is a LIGHTWEIGHT endpoint for when you only need to see what
    text is in the HTML and what its hashes are, but don't need the
    full html_dict structure.
    
    Use case: Quick inspection of text content before deciding to
    perform full hash replacement workflow.
    """
    # Parse HTML
    html_dict = self.html_direct_transformations.html__to__html_dict(request.html)
    
    # Extract text nodes
    extractor = Html__Extract_Text_Nodes()
    extractor.html_dict = html_dict
    extractor.max_depth = request.max_depth
    extractor.traverse(html_dict, depth=0, parent_tag=None)
    
    # Get mapping
    text_hashes_mapping = extractor.text_elements__raw
    
    return Schema__Html__To__Text__Hashes__Response(
        text_hashes_mapping  = text_hashes_mapping,
        total_text_hashes    = len(text_hashes_mapping),
        max_depth_reached    = self._check_depth(html_dict, request.max_depth)
    )
```

**MODIFY the `setup_routes()` method:**
```python
def setup_routes(self):
    self.add_route_post(self.to__dict         )             # Atomic operations
    self.add_route_post(self.to__html         )
    self.add_route_post(self.to__text__nodes  )             # Compound operations
    self.add_route_post(self.to__lines        )
    self.add_route_post(self.to__html__hashes )
    self.add_route_post(self.to__html__xxx    )
    self.add_route_post(self.to__dict__hashes )             # NEW: Hash workflow
    self.add_route_post(self.to__text__hashes )             # NEW: Hash workflow
```

---

## üîÑ Complete Working Workflow

### Example: Replacing "Hello" with "Goodbye"

#### Step 1: Get html_dict with hashes
```bash
POST /html/to__dict__hashes
Content-Type: application/json

{
  "html": "<html><body><p>Hello World</p></body></html>",
  "max_depth": 256
}
```

**Response:**
```json
{
  "html_dict": {
    "tag": "html",
    "nodes": [
      {
        "tag": "body",
        "nodes": [
          {
            "tag": "p",
            "nodes": [
              {
                "type": "TEXT",
                "data": "8b1a9953c4"
              },
              {
                "type": "TEXT",
                "data": "f6dd732dc8"
              }
            ]
          }
        ]
      }
    ]
  },
  "text_hashes_mapping": {
    "8b1a9953c4": "Hello ",
    "f6dd732dc8": "World"
  },
  "node_count": 7,
  "max_depth": 4,
  "total_text_hashes": 2,
  "max_depth_reached": false
}
```

#### Step 2: User creates hash_mapping
Looking at `text_hashes_mapping`, user decides to change "Hello " to "Goodbye ":
```json
{
  "8b1a9953c4": "Goodbye "
}
```

#### Step 3: Apply hash mapping
```bash
POST /hashes/to__html
Content-Type: application/json

{
  "html_dict": <from Step 1>,
  "hash_mapping": {
    "8b1a9953c4": "Goodbye "
  }
}
```

**Response:**
```html
<html><body><p>Goodbye World</p></body></html>
```

‚úÖ **SUCCESS!** Workflow complete in 2 API calls.

---

## üß™ Testing Requirements

### Unit Tests

Create test file: `tests/unit/test_routes_html_hashes.py`

```python
import pytest
from mgraph_ai_service_html.html__fast_api.routes.Routes__Html import Routes__Html
from mgraph_ai_service_html.html__fast_api.schemas.html.Schema__Html__To__Dict__Hashes__Request import Schema__Html__To__Dict__Hashes__Request
from mgraph_ai_service_html.html__fast_api.schemas.html.Schema__Html__To__Text__Hashes__Request import Schema__Html__To__Text__Hashes__Request

class Test_Routes__Html__Hash_Endpoints:
    
    def setup_method(self):
        self.routes = Routes__Html()
    
    def test_to__dict__hashes__simple_html(self):
        """Test basic HTML parsing with hash replacement"""
        request = Schema__Html__To__Dict__Hashes__Request(
            html="<p>Hello</p>"
        )
        
        response = self.routes.to__dict__hashes(request)
        
        # Verify response structure
        assert response.html_dict is not None
        assert response.text_hashes_mapping is not None
        assert response.total_text_hashes == 1
        assert response.node_count > 0
        
        # Verify hash is in mapping
        hash_value = list(response.text_hashes_mapping.keys())[0]
        assert response.text_hashes_mapping[hash_value] == "Hello"
        
        # Verify html_dict has hash, not text
        # Navigate to text node and check it contains hash
        assert hash_value in str(response.html_dict)
        assert "Hello" not in str(response.html_dict)
    
    def test_to__dict__hashes__multiple_text_nodes(self):
        """Test HTML with multiple text nodes"""
        request = Schema__Html__To__Dict__Hashes__Request(
            html="<div><p>First</p><p>Second</p></div>"
        )
        
        response = self.routes.to__dict__hashes(request)
        
        assert response.total_text_hashes == 2
        assert "First" in response.text_hashes_mapping.values()
        assert "Second" in response.text_hashes_mapping.values()
    
    def test_to__dict__hashes__nested_html(self):
        """Test deeply nested HTML"""
        request = Schema__Html__To__Dict__Hashes__Request(
            html="<div><p>Outer<b>Inner</b>End</p></div>"
        )
        
        response = self.routes.to__dict__hashes(request)
        
        assert response.total_text_hashes == 3
        assert "Outer" in response.text_hashes_mapping.values()
        assert "Inner" in response.text_hashes_mapping.values()
        assert "End" in response.text_hashes_mapping.values()
    
    def test_to__text__hashes__simple(self):
        """Test lightweight text hashes extraction"""
        request = Schema__Html__To__Text__Hashes__Request(
            html="<p>Hello World</p>"
        )
        
        response = self.routes.to__text__hashes(request)
        
        assert response.text_hashes_mapping is not None
        assert response.total_text_hashes >= 1
        # Should contain the text
        assert any("Hello" in text or "World" in text 
                   for text in response.text_hashes_mapping.values())
    
    def test_to__dict__hashes__empty_tags(self):
        """Test HTML with empty tags"""
        request = Schema__Html__To__Dict__Hashes__Request(
            html="<div><p></p><span>Text</span></div>"
        )
        
        response = self.routes.to__dict__hashes(request)
        
        assert response.total_text_hashes == 1
        assert "Text" in response.text_hashes_mapping.values()
    
    def test_hash_workflow__end_to_end(self):
        """Test complete workflow: extract hashes, modify, reconstruct"""
        from mgraph_ai_service_html.html__fast_api.routes.Routes__Hashes import Routes__Hashes
        from mgraph_ai_service_html.html__fast_api.schemas.hashes.Schema__Hashes__To__Html__Request import Schema__Hashes__To__Html__Request
        
        # Step 1: Extract hashes
        request1 = Schema__Html__To__Dict__Hashes__Request(
            html="<p>Hello World</p>"
        )
        response1 = self.routes.to__dict__hashes(request1)
        
        # Step 2: Create hash mapping (change first text)
        hash_to_change = list(response1.text_hashes_mapping.keys())[0]
        hash_mapping = {hash_to_change: "MODIFIED"}
        
        # Step 3: Apply mapping
        routes_hashes = Routes__Hashes()
        request2 = Schema__Hashes__To__Html__Request(
            html_dict=response1.html_dict,
            hash_mapping=hash_mapping
        )
        response2 = routes_hashes.to__html(request2)
        
        # Verify
        html_result = response2.body.decode('utf-8')
        assert "MODIFIED" in html_result
        assert response1.text_hashes_mapping[hash_to_change] not in html_result
```

### Integration Tests

Test via HTTP requests:

```python
def test_dict_hashes_endpoint_via_http(client):
    """Test /html/to__dict__hashes via FastAPI test client"""
    response = client.post(
        "/html/to/dict/hashes",
        json={
            "html": "<p>Test</p>",
            "max_depth": 256
        }
    )
    
    assert response.status_code == 200
    data = response.json()
    assert "html_dict" in data
    assert "text_hashes_mapping" in data
    assert data["total_text_hashes"] > 0

def test_text_hashes_endpoint_via_http(client):
    """Test /html/to__text__hashes via FastAPI test client"""
    response = client.post(
        "/html/to/text/hashes",
        json={
            "html": "<p>Test</p>",
            "max_depth": 256
        }
    )
    
    assert response.status_code == 200
    data = response.json()
    assert "text_hashes_mapping" in data
    assert data["total_text_hashes"] > 0
```

---

## ‚úÖ Testing Checklist

### Unit Tests
- [ ] `to__dict__hashes` with simple HTML
- [ ] `to__dict__hashes` with multiple text nodes
- [ ] `to__dict__hashes` with nested elements
- [ ] `to__dict__hashes` with empty tags
- [ ] `to__dict__hashes` with special characters in text
- [ ] `to__text__hashes` with simple HTML
- [ ] `to__text__hashes` with complex HTML
- [ ] Complete workflow: extract ‚Üí modify ‚Üí reconstruct
- [ ] Verify hash format (10 characters)
- [ ] Verify text_hashes_mapping has correct format
- [ ] Verify html_dict has hashes, not text

### Integration Tests
- [ ] HTTP POST to `/html/to/dict/hashes` returns 200
- [ ] HTTP POST to `/html/to/text/hashes` returns 200
- [ ] Response schemas validate correctly
- [ ] OpenAPI docs show new endpoints
- [ ] End-to-end via HTTP: extract ‚Üí modify ‚Üí reconstruct

### Edge Cases
- [ ] HTML with no text nodes
- [ ] HTML with only whitespace
- [ ] HTML with scripts/styles (should be ignored)
- [ ] Very large HTML (performance test)
- [ ] Malformed HTML (should still work)
- [ ] HTML with special Unicode characters
- [ ] max_depth parameter works correctly

### Compatibility
- [ ] New endpoints don't break existing endpoints
- [ ] Old tests still pass
- [ ] API documentation updated
- [ ] Response format matches `Schema__Hashes__To__Html__Request` requirements

---

## üìä API Documentation Examples

### OpenAPI/Swagger Documentation

The new endpoints will appear in the OpenAPI docs at `/docs`:

**`POST /html/to/dict/hashes`**
```yaml
summary: Convert HTML to dict with text replaced by hashes
description: |
  Parses HTML and replaces all text content with 10-character MD5 hashes.
  Returns both the modified html_dict and a simple hash‚Üítext mapping.
  
  This is the primary endpoint for the hash replacement workflow:
  1. Call this endpoint with your HTML
  2. Modify the text_hashes_mapping to create your hash_mapping
  3. Call /hashes/to/html with html_dict + hash_mapping
  4. Receive your modified HTML
  
tags:
  - html
requestBody:
  content:
    application/json:
      schema:
        type: object
        properties:
          html:
            type: string
            description: Raw HTML content
          max_depth:
            type: integer
            default: 256
            description: Maximum tree traversal depth
responses:
  200:
    description: Successful response
    content:
      application/json:
        schema:
          type: object
          properties:
            html_dict:
              type: object
              description: HTML structure with text as hashes
            text_hashes_mapping:
              type: object
              description: Simple {hash: text} mapping
            node_count:
              type: integer
            max_depth:
              type: integer
            total_text_hashes:
              type: integer
            max_depth_reached:
              type: boolean
```

**`POST /html/to/text/hashes`**
```yaml
summary: Extract text hash mapping from HTML
description: |
  Lightweight endpoint that returns only the text‚Üíhash mapping
  without the full html_dict structure. Useful for quick inspection.
  
tags:
  - html
requestBody:
  content:
    application/json:
      schema:
        type: object
        properties:
          html:
            type: string
          max_depth:
            type: integer
            default: 256
responses:
  200:
    description: Successful response
    content:
      application/json:
        schema:
          type: object
          properties:
            text_hashes_mapping:
              type: object
            total_text_hashes:
              type: integer
            max_depth_reached:
              type: boolean
```

---

## üéØ Success Metrics

### Functional Success
‚úÖ Both endpoints return correct data structures  
‚úÖ `text_hashes_mapping` format matches `hash_mapping` input format  
‚úÖ `html_dict` has text replaced with hashes  
‚úÖ Complete workflow works end-to-end  
‚úÖ All tests pass  

### Performance Success
‚úÖ No performance regression on existing endpoints  
‚úÖ New endpoints complete in < 1 second for typical HTML  
‚úÖ Memory usage acceptable for large HTML documents  

### Code Quality Success
‚úÖ Type-safe schemas properly defined  
‚úÖ Code follows existing patterns in codebase  
‚úÖ Proper error handling  
‚úÖ Comprehensive docstrings  
‚úÖ No pylint/mypy warnings  

---

## üö® Important Notes

### DO NOT Modify Existing Code
- **DO NOT** change existing endpoint signatures
- **DO NOT** modify existing schemas
- **DO NOT** change existing method implementations
- **ONLY ADD** new methods and schemas

### Naming Conventions
- Use `text_hashes_mapping` (not `text_nodes_mapping`)
- Use `to__dict__hashes` (double underscore pattern)
- Follow existing schema naming: `Schema__<Source>__To__<Target>__<Type>`

### Import Organization
- Group imports by: stdlib, third-party, osbot_utils, mgraph_ai_service_html
- Use absolute imports
- Keep imports sorted alphabetically within groups

### Type Safety
- All schemas must inherit from `Type_Safe`
- Use proper type hints (Safe_Str__Hash, Safe_UInt, etc.)
- Dict keys must be properly typed

---

## üìö References

### Existing Code to Reference
- `Routes__Html.to__text__nodes()` - Similar extraction logic
- `Routes__Hashes.to__html()` - Consumer of our output
- `Html__Extract_Text_Nodes` - Core extraction class
- `Schema__Html__To__Text__Nodes__Response` - Similar response pattern

### Related Files
- `mgraph_ai_service_html/html__fast_api/routes/Routes__Html.py`
- `mgraph_ai_service_html/html__fast_api/routes/Routes__Hashes.py`
- `mgraph_ai_service_html/html__fast_api/core/Html__Extract_Text_Nodes.py`
- `mgraph_ai_service_html/html__fast_api/core/Html__Direct__Transformations.py`

---

## üéì Implementation Guidelines

1. **Create schema files first** - Ensures type safety from the start
2. **Implement methods second** - Use schemas for type hints
3. **Register routes third** - Add to setup_routes()
4. **Write tests last** - Verify everything works
5. **Test existing endpoints** - Ensure no regressions

---

## ‚ú® Final Checklist

Before marking this implementation complete, verify:

- [ ] All 4 schema files created in correct locations
- [ ] Both methods added to Routes__Html class
- [ ] Both routes registered in setup_routes()
- [ ] All imports added correctly
- [ ] Unit tests created and passing
- [ ] Integration tests created and passing
- [ ] OpenAPI docs show new endpoints
- [ ] Complete workflow tested end-to-end
- [ ] No existing tests broken
- [ ] Code follows project conventions
- [ ] All docstrings complete
- [ ] No lint errors
